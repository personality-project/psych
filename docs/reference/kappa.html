<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Find Cohen's kappa and weighted kappa coefficients for correlation of two raters — cohen.kappa • psych</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>

<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">psych</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Find Cohen's kappa and weighted kappa coefficients for correlation of two raters</h1>
    </div>

    
    <p>Cohen's kappa (Cohen, 1960) and weighted kappa (Cohen, 1968) may be used to find the agreement of two raters when using nominal scores.</p>
<p>weighted.kappa is (probability of observed matches - probability of expected matches)/(1 - probability of expected matches).  Kappa just considers the matches on the main diagonal.  Weighted kappa considers off diagonal elements as well.</p>
    

    <pre class="usage"><span class='fu'>cohen.kappa</span>(<span class='no'>x</span>, <span class='kw'>w</span><span class='kw'>=</span><span class='kw'>NULL</span>,<span class='kw'>n.obs</span><span class='kw'>=</span><span class='kw'>NULL</span>,<span class='kw'>alpha</span><span class='kw'>=</span><span class='fl'>.05</span>,<span class='kw'>levels</span><span class='kw'>=</span><span class='kw'>NULL</span>)
<span class='fu'>wkappa</span>(<span class='no'>x</span>, <span class='kw'>w</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)    <span class='co'>#deprectated</span></pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a> Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>Either a two by n data with categorical values from 1 to p or a p x p table.  If a data array, a table will be found.</p></td>
    </tr>
    <tr>
      <th>w</th>
      <td><p>A p x p matrix of weights.  If not specified, they are set to be 0 (on the diagonal) and (distance from diagonal) off the diagonal)^2.</p></td>
    </tr>
    <tr>
      <th>n.obs</th>
      <td><p>Number of observations (if input is a square matrix.</p></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>Probability level for confidence intervals</p></td>
    </tr>
    <tr>
      <th>levels</th>
      <td><p>Specify the number of levels if some levels of x or y are completely missing</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>When cateogorical judgments are made with two cateories, a measure of relationship is the phi coefficient.  However, some categorical judgments are made using more than two outcomes.  For example, two diagnosticians might be asked to categorize patients three ways (e.g., Personality disorder, Neurosis, Psychosis) or to categorize the stages of a disease.  Just as base rates affect observed cell frequencies in a two by two table, they need to be considered in the n-way table (Cohen, 1960).</p>
<p>Kappa considers the matches on the main diagonal.  A penalty function (weight) may be applied to the off diagonal matches.  If the weights increase by the square of the distance from the diagonal, weighted kappa is similar to an Intra Class Correlation (<code><a href='ICC.html'>ICC</a></code>).</p>
<p>Derivations of weighted kappa are sometimes expressed in terms of similarities, and sometimes in terms of dissimilarities. In the latter case, the weights on the diagonal are 1 and the weights off the diagonal are less than one. In this, if the weights are 1 - squared distance from the diagonal / k, then the result is similar to the ICC (for any positive k).</p>
<p>cohen.kappa may use either similarity weighting (diagonal = 0) or dissimilarity weighting (diagonal = 1) in order to match various published examples.</p>
<p>The input may be a two column data.frame or matrix with columns representing the two judges and rows the subjects being rated. Alternatively, the input may be a square n x n matrix of counts or proportion of matches.  If proportions are used, it is necessary to specify the number of observations (n.obs) in order to correctly find the confidence intervals.</p>
<p>The confidence intervals are based upon the variance estimates discussed by Fleiss, Cohen, and Everitt who corrected the formulae of Cohen (1968) and Blashfield.</p>
<p>Some data sets will include data with numeric categories with some category values missing completely.  In the sense that kappa is a measure of category relationship, this should not matter.  But when finding weighted kappa, the number of categories weighted will be less than the number of categories potentially in the data.  This can be remedied by specifying the levels parameter.</p>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p></p>
<dt>kappa </dt><dd><p>Unweighted kappa</p></dd>
  <dt>weighted.kappa </dt><dd><p>The default weights are quadratric.</p></dd>
  <dt>var.kappa</dt><dd><p>Variance of kappa</p></dd>
  <dt>var.weighted</dt><dd><p>Variance of weighted kappa</p></dd>
  <dt>n.obs</dt><dd><p>number of observations</p></dd>
  <dt>weight</dt><dd><p>The weights used in the estimation of weighted kappa</p></dd>
  <dt>confid</dt><dd><p>The alpha/2 confidence intervals for unweighted and weighted kappa</p></dd>
  <dt>plevel</dt><dd><p>The alpha level used in determining the confidence limits</p></dd>

    
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Banerjee, M., Capozzoli, M., McSweeney, L and Sinha, D. (1999) Beyond Kappa: A review of interrater agreement measures The Canadian Journal of Statistics / La Revue Canadienne de Statistique, 27, 3-23</p>
<p>Cohen, J. (1960). A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20 37-46</p>
<p>Cohen, J. (1968). Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit. Psychological Bulletin, 70, 213-220.</p>
<p>Fleiss, J. L., Cohen, J.  and Everitt, B.S. (1969) Large sample standard errors of kappa and weighted kappa. Psychological Bulletin, 72, 332-327.</p>
<p>Zwick, R.  (1988) Another look at interrater agreement. Psychological Bulletin, 103, 374 - 378.</p>
<p></p>
    
    <h2 class="hasAnchor" id="note"><a class="anchor" href="#note"></a>Note</h2>

    <p>As is true of many R functions, there are alternatives in other packages.  The Kappa function in the vcd package estimates unweighted and weighted kappa and reports the variance of the estimate. The input is a square matrix. The ckappa and wkappa functions in the psy package take raw data matrices.</p>
<p>To avoid confusion with Kappa (from vcd) or the kappa function from base, the function was originally named wkappa. With additional features modified from psy::ckappa to allow input with a different number of categories, the function has been renamed cohen.kappa.</p>
<p>Unfortunately, to make it more confusing, the weights described by Cohen are a function of the reciprocals of those discucssed by Fleiss and Cohen. The cohen.kappa function uses the appropriate formula for Cohen or Fleiss-Cohen weights.</p>
<p>There are some cases where the large sample size approximation of Fleiss et al. will produce confidence intervals exceeding +/- 1.  Clearly, for these cases, the upper (or lower for negative values) should be set to 1.  Boot strap resampling shows the problem is that the values are not symmetric.  See the last (unrun) example.</p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'>
<span class='co'>#rating data (with thanks to Tim Bates)</span>
<span class='no'>rater1</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>1</span>,<span class='fl'>2</span>,<span class='fl'>3</span>,<span class='fl'>4</span>,<span class='fl'>5</span>,<span class='fl'>6</span>,<span class='fl'>7</span>,<span class='fl'>8</span>,<span class='fl'>9</span>) <span class='co'># rater one's ratings</span>
<span class='no'>rater2</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>1</span>,<span class='fl'>3</span>,<span class='fl'>1</span>,<span class='fl'>6</span>,<span class='fl'>1</span>,<span class='fl'>5</span>,<span class='fl'>5</span>,<span class='fl'>6</span>,<span class='fl'>7</span>) <span class='co'># rater one's ratings</span>
<span class='fu'>cohen.kappa</span>(<span class='kw'>x</span><span class='kw'>=</span><span class='fu'>cbind</span>(<span class='no'>rater1</span>,<span class='no'>rater2</span>))</div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa -0.18     0.00  0.18
#&gt; weighted kappa    0.43     0.68  0.93
#&gt; 
#&gt;  Number of subjects = 9 </div><div class='input'>
<span class='co'>#data matrix taken from Cohen</span>
<span class='no'>cohen</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
<span class='fl'>0.44</span>, <span class='fl'>0.07</span>, <span class='fl'>0.09</span>,
<span class='fl'>0.05</span>, <span class='fl'>0.20</span>, <span class='fl'>0.05</span>,
<span class='fl'>0.01</span>, <span class='fl'>0.03</span>, <span class='fl'>0.06</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>3</span>,<span class='kw'>byrow</span><span class='kw'>=</span><span class='fl'>TRUE</span>)

<span class='co'>#cohen.weights  weight differences</span>
<span class='no'>cohen.weights</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
<span class='fl'>0</span>,<span class='fl'>1</span>,<span class='fl'>3</span>,
<span class='fl'>1</span>,<span class='fl'>0</span>,<span class='fl'>6</span>,
<span class='fl'>3</span>,<span class='fl'>6</span>,<span class='fl'>0</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>3</span>)


<span class='fu'>cohen.kappa</span>(<span class='no'>cohen</span>,<span class='no'>cohen.weights</span>,<span class='kw'>n.obs</span><span class='kw'>=</span><span class='fl'>200</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa  0.39     0.49  0.59
#&gt; weighted kappa   -0.39     0.35  1.00
#&gt; 
#&gt;  Number of subjects = 200 </div><div class='input'><span class='co'>#cohen reports .492 and .348 </span>

<span class='co'>#another set of weights</span>
<span class='co'>#what if the weights are non-symmetric</span>
<span class='no'>wc</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
<span class='fl'>0</span>,<span class='fl'>1</span>,<span class='fl'>4</span>,
<span class='fl'>1</span>,<span class='fl'>0</span>,<span class='fl'>6</span>,
<span class='fl'>2</span>,<span class='fl'>2</span>,<span class='fl'>0</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>3</span>,<span class='kw'>byrow</span><span class='kw'>=</span><span class='fl'>TRUE</span>)
<span class='fu'>cohen.kappa</span>(<span class='no'>cohen</span>,<span class='no'>wc</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa -0.92     0.49     1
#&gt; weighted kappa   -1.00     0.35     1
#&gt; 
#&gt;  Number of subjects = 1 </div><div class='input'><span class='co'>#Cohen reports kw = .353</span>

<span class='fu'>cohen.kappa</span>(<span class='no'>cohen</span>,<span class='kw'>n.obs</span><span class='kw'>=</span><span class='fl'>200</span>)  <span class='co'>#this uses the squared weights</span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa  0.39     0.49  0.59
#&gt; weighted kappa    0.32     0.45  0.58
#&gt; 
#&gt;  Number of subjects = 200 </div><div class='input'>
<span class='no'>fleiss.cohen</span> <span class='kw'>&lt;-</span> <span class='fl'>1</span> - <span class='no'>cohen.weights</span>/<span class='fl'>9</span>
<span class='fu'>cohen.kappa</span>(<span class='no'>cohen</span>,<span class='no'>fleiss.cohen</span>,<span class='kw'>n.obs</span><span class='kw'>=</span><span class='fl'>200</span>)</div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa  0.39     0.49  0.59
#&gt; weighted kappa    0.20     0.35  0.50
#&gt; 
#&gt;  Number of subjects = 200 </div><div class='input'>
<span class='co'>#however, Fleiss, Cohen and Everitt weight similarities</span>
<span class='no'>fleiss</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
<span class='fl'>106</span>, <span class='fl'>10</span>,<span class='fl'>4</span>,
<span class='fl'>22</span>,<span class='fl'>28</span>, <span class='fl'>10</span>,
<span class='fl'>2</span>, <span class='fl'>12</span>,  <span class='fl'>6</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>3</span>,<span class='kw'>byrow</span><span class='kw'>=</span><span class='fl'>TRUE</span>)

<span class='co'>#Fleiss weights the similarities</span>
<span class='no'>weights</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
 <span class='fl'>1.0000</span>, <span class='fl'>0.0000</span>, <span class='fl'>0.4444</span>,
 <span class='fl'>0.0000</span>, <span class='fl'>1.0000</span>, <span class='fl'>0.6667</span>,
 <span class='fl'>0.4444</span>, <span class='fl'>0.6667</span>, <span class='fl'>1.0000</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>3</span>)

 <span class='fu'>cohen.kappa</span>(<span class='no'>fleiss</span>,<span class='no'>weights</span>,<span class='kw'>n.obs</span><span class='kw'>=</span><span class='fl'>200</span>)</div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa  0.32     0.43  0.53
#&gt; weighted kappa    0.40     0.51  0.62
#&gt; 
#&gt;  Number of subjects = 200 </div><div class='input'>
 <span class='co'>#another example is comparing the scores of two sets of twins</span>
 <span class='co'>#data may be a 2 column matrix</span>
 <span class='co'>#compare weighted and unweighted</span>
 <span class='co'>#also look at the ICC for this data set.</span>
 <span class='no'>twins</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>c</span>(
    <span class='fl'>1</span>, <span class='fl'>2</span>,
    <span class='fl'>2</span>, <span class='fl'>3</span>,
    <span class='fl'>3</span>, <span class='fl'>4</span>,
    <span class='fl'>5</span>, <span class='fl'>6</span>,
    <span class='fl'>6</span>, <span class='fl'>7</span>), <span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>2</span>,<span class='kw'>byrow</span><span class='kw'>=</span><span class='fl'>TRUE</span>)
  <span class='fu'>cohen.kappa</span>(<span class='no'>twins</span>)</div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate  upper
#&gt; unweighted kappa -0.23    -0.14 -0.046
#&gt; weighted kappa    0.80     0.87  0.942
#&gt; 
#&gt;  Number of subjects = 5 </div><div class='input'>
<span class='co'>#data may be explicitly categorical</span>
<span class='no'>x</span> <span class='kw'>&lt;-</span> <span class='fu'>c</span>(<span class='st'>"red"</span>,<span class='st'>"yellow"</span>,<span class='st'>"blue"</span>,<span class='st'>"red"</span>)
<span class='no'>y</span> <span class='kw'>&lt;-</span> <span class='fu'>c</span>(<span class='st'>"red"</span>,  <span class='st'>"blue"</span>, <span class='st'>"blue"</span> ,<span class='st'>"red"</span>)
<span class='no'>xy.df</span> <span class='kw'>&lt;-</span> <span class='fu'>data.frame</span>(<span class='no'>x</span>,<span class='no'>y</span>)
<span class='no'>ck</span> <span class='kw'>&lt;-</span> <span class='fu'>cohen.kappa</span>(<span class='no'>xy.df</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='input'><span class='no'>ck</span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                   lower estimate upper
#&gt; unweighted kappa  0.098      0.6  1.00
#&gt; weighted kappa   -0.693      0.0  0.69
#&gt; 
#&gt;  Number of subjects = 4 </div><div class='input'><span class='no'>ck</span>$<span class='no'>agree</span></div><div class='output co'>#&gt;         x2f
#&gt; x1f      blue  red yellow
#&gt;   blue   0.25 0.00   0.00
#&gt;   red    0.00 0.50   0.00
#&gt;   yellow 0.25 0.00   0.00</div><div class='input'>
<span class='co'>#The problem of missing categories (from Amy Finnegan)</span>
<span class='no'>numbers</span> <span class='kw'>&lt;-</span> <span class='fu'>data.frame</span>(<span class='kw'>rater1</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>6</span>,<span class='fl'>3</span>,<span class='fl'>7</span>,<span class='fl'>8</span>,<span class='fl'>7</span>),
                      <span class='kw'>rater2</span><span class='kw'>=</span><span class='fu'>c</span>(<span class='fl'>6</span>,<span class='fl'>1</span>,<span class='fl'>8</span>,<span class='fl'>5</span>,<span class='fl'>10</span>))
<span class='fu'>cohen.kappa</span>(<span class='no'>numbers</span>)  <span class='co'>#compare with the next analysis</span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                   lower estimate upper
#&gt; unweighted kappa -0.161     0.13  0.42
#&gt; weighted kappa   -0.037     0.53  1.00
#&gt; 
#&gt;  Number of subjects = 5 </div><div class='input'><span class='fu'>cohen.kappa</span>(<span class='no'>numbers</span>,<span class='kw'>levels</span><span class='kw'>=</span><span class='fl'>1</span>:<span class='fl'>10</span>)  <span class='co'>#specify the number of levels </span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; Call: cohen.kappa1(x = x, w = w, n.obs = n.obs, alpha = alpha, levels = levels)
#&gt; 
#&gt; Cohen Kappa and Weighted Kappa correlation coefficients and confidence boundaries 
#&gt;                  lower estimate upper
#&gt; unweighted kappa -0.16     0.13  0.42
#&gt; weighted kappa    0.23     0.62  1.00
#&gt; 
#&gt;  Number of subjects = 5 </div><div class='input'>              <span class='co'>#   these leads to slightly higher weighted kappa</span>

<span class='co'>#finally, input can be a data.frame of ratings from more than two raters</span>
<span class='no'>ratings</span> <span class='kw'>&lt;-</span> <span class='fu'>matrix</span>(<span class='fu'>rep</span>(<span class='fl'>1</span>:<span class='fl'>5</span>,<span class='fl'>4</span>),<span class='kw'>ncol</span><span class='kw'>=</span><span class='fl'>4</span>)
<span class='no'>ratings</span>[<span class='fl'>1</span>,<span class='fl'>2</span>] <span class='kw'>&lt;-</span> <span class='no'>ratings</span>[<span class='fl'>2</span>,<span class='fl'>3</span>] <span class='kw'>&lt;-</span> <span class='no'>ratings</span>[<span class='fl'>3</span>,<span class='fl'>4</span>] <span class='kw'>&lt;-</span> <span class='fl'>NA</span>
<span class='no'>ratings</span>[<span class='fl'>2</span>,<span class='fl'>1</span>] <span class='kw'>&lt;-</span> <span class='no'>ratings</span>[<span class='fl'>3</span>,<span class='fl'>2</span>] <span class='kw'>&lt;-</span> <span class='no'>ratings</span>[<span class='fl'>4</span>,<span class='fl'>3</span>] <span class='kw'>&lt;-</span> <span class='fl'>1</span>
<span class='fu'>cohen.kappa</span>(<span class='no'>ratings</span>)</div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; <span class='warning'>Warning: upper or lower confidence interval exceed  abs(1)  and set to +/- 1. </span></div><div class='output co'>#&gt; 
#&gt; Cohen Kappa (below the diagonal) and Weighted Kappa (above the diagonal) 
#&gt; For confidence intervals and detail print with all=TRUE
#&gt;      R1   R2   R3   R4
#&gt; R1 1.00 0.74 0.67 0.92
#&gt; R2 0.38 1.00 0.48 1.00
#&gt; R3 0.67 0.14 1.00 0.80
#&gt; R4 0.67 1.00 0.50 1.00</div><div class='input'>

 <span class='co'>#In the case of confidence intervals being artificially truncated to +/- 1, it is </span>
 <span class='co'>#helpful to compare the results of a boot strap resample</span>
 <span class='co'>#ck.boot &lt;-function(x,s=1:nrow(x)) {cohen.kappa(x[s,])$kappa}</span>
 <span class='co'>#library(boot)</span>
 <span class='co'>#ckb &lt;- boot(x,ck.boot,R=1000)</span>
 <span class='co'>#hist(ckb$t)</span></div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#details">Details</a></li>

      <li><a href="#value">Value</a></li>

      <li><a href="#references">References</a></li>

      <li><a href="#note">Note</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    William Revelle 
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by William Revelle.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
